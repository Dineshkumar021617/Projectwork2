## AI VOICE DISCRIMINATION USING DEEP LEARNING
The development of an AI-powered voice discrimination system designed to enhance security measures and user authentication processes in various applications and industries.

## About
Artificial Intelligence (AI) Voice Discrimination System is an innovative project aimed at implementing a cutting-edge AI algorithm capable of accurately discriminating between different human voices. This system utilizes state-of-the-art machine learning techniques to analyze and distinguish unique vocal characteristics, enabling precise identification and authentication of individuals based on their voice patterns. By harnessing the power of AI, this project aims to enhance security measures and authentication processes across various domains, offering a seamless and reliable solution for voice-based identification.

## Features
- Implementation of advanced machine learning algorithms for voice analysis and discrimination.
- Development of a robust framework for deploying the AI voice discrimination system across various platforms.
- High scalability to accommodate a large volume of voice data and users.
- Optimized for minimal time complexity, ensuring efficient processing and response times.
- Utilization of a specific model for voice discrimination, leveraging JSON data format for streamlined integration and compatibility.

## Requirements
* Operating System: Requires a 64-bit OS (Windows 10 or Ubuntu) for compatibility with deep learning frameworks.
* Development Environment: Python 3.8 or later is necessary for coding the AI voice discrimination system.
* Deep Learning Frameworks: TensorFlow for model training and inference.
* Audio Processing Libraries: Librosa for audio feature extraction and processing.
* Version Control: Implementation of Git for collaborative development and effective code management.
* IDE: Use of Jupyter Notebook or VSCode as the Integrated Development Environment for coding, debugging, and version control integration.
* Additional Dependencies: Includes NumPy, Pandas, Scikit-learn, and TensorFlow (versions 2.6.0) for deep learning tasks.

## System Architecture
![image](https://github.com/Dineshkumar021617/Projectwork2/assets/75234807/48f3fc5d-6123-4f63-80d4-ce289b0729ba)


## Output

<!--Embed the Output picture at respective places as shown below as shown below-->
#### Output1
![image](https://github.com/Dineshkumar021617/Projectwork2/assets/75234807/2645d43d-2075-4435-a883-d46f6199cad3)


#### Output2
![image](https://github.com/Dineshkumar021617/Projectwork2/assets/75234807/0a055f6a-fd9f-4fda-8804-e79132aec36d)



## Results and Impact
<!--Give the results and impact as shown below-->
The AI Voice Discrimination System enhances the accuracy and reliability of voice-based authentication systems, contributing to improved security and user experience in various applications. By leveraging advanced machine learning algorithms, the system achieves high levels of accuracy in distinguishing between genuine and synthetic voices.

This project has significant implications for security-sensitive industries such as banking, telecommunications, and healthcare, where voice authentication plays a crucial role in identity verification and fraud prevention. Additionally, it can enhance user privacy by mitigating the risk of unauthorized access through voice impersonation.

The AI Voice Discrimination System opens up possibilities for innovative applications in voice-controlled devices, virtual assistants, and personalized user experiences. Its deployment has the potential to revolutionize the way users interact with technology, paving the way for more seamless and secure voice-enabled systems.


## Articles published / References
[1] A survey on deep reinforcement learning for audio-based applications, 2022, 
[2] Ballesteros, D.M.; Rodriguez-Ortega, Y.; Renza, D.; Arce, G. Deep4SNet: Deep learning for fake speech classification. Expert Syst. Appl. 2021
[3] Voice Activity Detection (VAD) in Noisy Environments, Joshua Ball,Johns Hopkins University,Department of Electrical and Computer Engineering,IEEE 
[4] Ning, Y.; He, S.; Wu, Z.; Xing, C.; Zhang, L.-J. A Review of Deep Learning Based Speech Synthesis. Appl. Sci. 2019
[5] Carrara N, Laroche R, Pietquin O (2017) Online learning and transfer for user adaptation in dialogue systems. In: SIGDIAL/SEMDIAL joint special session on negotiation dialog 2017
[6] Borrelli, C.; Bestagini, P.; Antonacci, F.; Sarti, A.; Tubaro, S. Synthetic speech detection through short-term and long-term prediction traces. EURASIP J. Inf. Secur. 2021, 2021
[7] Reimao, R.; Tzerpos, V. For: A dataset for synthetic speech detection. In Proceedings of the 2019 International Conference on Speech Technology and Human-Computer Dialogue (SpeD), Timisoara, Romania, 10 October 2019
[8] SudhiFinn C, Abbeel P, Levine S (2017) Model-agnostic meta-learning for fast adaptation of deep networks. In: International Conference on Machine Learning (ICML) 
[9] Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y (2014) Generative adversarial nets. In: Advances in Neural Information Processing Systems (NIPS)
[10] Shan, M.; Tsai, T. A cross-verification approach for protecting world leaders from fake and tampered audio. arXiv 2020
[11] Li J, Deng L, Haeb-Umbach R, Gong Y (2015) Robust automatic speech recognition: a bridge to practical applications. Academic Press
[12] ajafian, M. Modeling accents for automatic speech recognition. In Proceedings of the 23rd European Signal Proceedings (EUSIPCO), Nice, France, 31 Augustâ€“4 September 2015; University of Birmingham: Birmingham, UK, 2013
[13] Schaul T, Quan J, Antonoglou I, Silver D (2016) Prioritized experience replay. International Conference on Learning Representations (ICLR)
[14] Wang R, Ao J, Zhou L, Liu S, Wei Z, Ko T, Li Q, Zhang Y (2021) Multi-view self-attention based transformer for speaker recognition. arXiv preprint
[15] Jain, D.; Beniwal, D.P. Review paper on noise cancellation using adaptive filters. Int. J. Eng. Res. Technol. 2022





